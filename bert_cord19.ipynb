{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_cord19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3aa40b7fda134e11a09a94a0106d59c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_63c2ff14e99f400aa69a6cdae6dea58d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0716d94ae25a4ee18d609c76570b64c4",
              "IPY_MODEL_80f60742dbb04977b269ebf565bc1597"
            ]
          }
        },
        "63c2ff14e99f400aa69a6cdae6dea58d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0716d94ae25a4ee18d609c76570b64c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_173b7aa887c04e9098891c7db83865ad",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2199ce3aaa3b4618a3dd77f9dc2d23e8"
          }
        },
        "80f60742dbb04977b269ebf565bc1597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_15f52fc47ded4417a48354878a040396",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:04&lt;00:00, 95.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1131ea44b9a41e8bec401eeb0afa7a9"
          }
        },
        "173b7aa887c04e9098891c7db83865ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2199ce3aaa3b4618a3dd77f9dc2d23e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15f52fc47ded4417a48354878a040396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1131ea44b9a41e8bec401eeb0afa7a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "803ad22e467942f7b1e6dfdc78a1f5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_385320cf139849db9396528bbaf7b146",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ea69f8ce5f024a5ca5cdaed7a8b3669f",
              "IPY_MODEL_a39dd28b75914bf589e4ae086d14d812"
            ]
          }
        },
        "385320cf139849db9396528bbaf7b146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea69f8ce5f024a5ca5cdaed7a8b3669f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7af47f79666f4c919fabf9aa61a993e9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62c2028372ce4b4da18fbde2eac6df98"
          }
        },
        "a39dd28b75914bf589e4ae086d14d812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06921d19457d4408bbd2ea82040e8d32",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:04&lt;00:00, 63.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9af2971c6b14556930dddb0afd45e08"
          }
        },
        "7af47f79666f4c919fabf9aa61a993e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62c2028372ce4b4da18fbde2eac6df98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06921d19457d4408bbd2ea82040e8d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9af2971c6b14556930dddb0afd45e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee7633f7e5804b3299a6bf0fcdf13da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ccf203d3926844feb53d16ec50ba1872",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a2705782a1bf428496079556ed3fe17e",
              "IPY_MODEL_7b6ba9d4c4d14270acae5796c4f8d24f"
            ]
          }
        },
        "ccf203d3926844feb53d16ec50ba1872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2705782a1bf428496079556ed3fe17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a54855d6151a43bf9c783f75b0a94b37",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad9581fd96e54b02920a94bbf88f3834"
          }
        },
        "7b6ba9d4c4d14270acae5796c4f8d24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d404ba03ca044cf3b0b6fe06f616dc70",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:02&lt;00:00, 116kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5f0d38b7eb44d67966f33967c4fbe52"
          }
        },
        "a54855d6151a43bf9c783f75b0a94b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad9581fd96e54b02920a94bbf88f3834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d404ba03ca044cf3b0b6fe06f616dc70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5f0d38b7eb44d67966f33967c4fbe52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc79ee944c5442289ed33275bcdba802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cb3874ff991d4954bd46a4bdbb571add",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c4ec60ce203f4e8099896b73f143d3a2",
              "IPY_MODEL_0392a76e9cf24bbdb79b3081040265a6"
            ]
          }
        },
        "cb3874ff991d4954bd46a4bdbb571add": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4ec60ce203f4e8099896b73f143d3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57c09b4595814bb899aef7a7e790d669",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ca6595fa8b84aa4875974048c2fdfe0"
          }
        },
        "0392a76e9cf24bbdb79b3081040265a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9546bbb257d949a5a19adb52c52bfb6a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 47.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43d6bc60eb0048a7a460ba5994cef43d"
          }
        },
        "57c09b4595814bb899aef7a7e790d669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ca6595fa8b84aa4875974048c2fdfe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9546bbb257d949a5a19adb52c52bfb6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43d6bc60eb0048a7a460ba5994cef43d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89a4232131d24ba4ad0a62d48837378a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a344484697d14f70bc57babe2daa058d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8ef453aa697d4feab603a72ca1a2d58c",
              "IPY_MODEL_285a45b82d154f11ae3fdab3cf9a6fc3"
            ]
          }
        },
        "a344484697d14f70bc57babe2daa058d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ef453aa697d4feab603a72ca1a2d58c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0920ca190ca7428888c18e11a169e86c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e43f9e761904716ae4f3907508ae8c0"
          }
        },
        "285a45b82d154f11ae3fdab3cf9a6fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_276ce04d482942759c29fb2bb9bc1744",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.04MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3538333f3f04b23a8a3e5180738509b"
          }
        },
        "0920ca190ca7428888c18e11a169e86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e43f9e761904716ae4f3907508ae8c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "276ce04d482942759c29fb2bb9bc1744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3538333f3f04b23a8a3e5180738509b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93aa42fa5d5344abad1add36c43c2d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_696477a3b5b94005aa00a30e6478c60e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4e54869cec9a461ca6ebaca705267c8e",
              "IPY_MODEL_b5f09093779a42d0be0cacdb07733021"
            ]
          }
        },
        "696477a3b5b94005aa00a30e6478c60e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e54869cec9a461ca6ebaca705267c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_783c82e8a35d4de7825f8bd72346ef0c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 443,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 443,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_118f5de11b0e431ea523742c1ad65041"
          }
        },
        "b5f09093779a42d0be0cacdb07733021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3279c562a5064831b9fecdfc45c1505e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 443/443 [00:21&lt;00:00, 20.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8234f20035e48b98fda65461a24c98f"
          }
        },
        "783c82e8a35d4de7825f8bd72346ef0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "118f5de11b0e431ea523742c1ad65041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3279c562a5064831b9fecdfc45c1505e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8234f20035e48b98fda65461a24c98f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cedcc8af0a04b50a2854d5275319510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_70c808952a044f098f8fd3728f0f5e13",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7609b415a0cf4223b55041a201635775",
              "IPY_MODEL_2e0598e7fd964c769c6b3cd6e122dacc"
            ]
          }
        },
        "70c808952a044f098f8fd3728f0f5e13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7609b415a0cf4223b55041a201635775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ace10325e284e5e8bbe7f493b3a383a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1340675298,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1340675298,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3edcb8a88346434a92f45e9c05188767"
          }
        },
        "2e0598e7fd964c769c6b3cd6e122dacc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_003af04543644465b52f9b2298729bf7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [00:21&lt;00:00, 63.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a81cc0e0bd944364baa212841b5cb625"
          }
        },
        "1ace10325e284e5e8bbe7f493b3a383a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3edcb8a88346434a92f45e9c05188767": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "003af04543644465b52f9b2298729bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a81cc0e0bd944364baa212841b5cb625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "642d1cb8685f4c3893a802cd3eb0939c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c227d8c0bd6b44dbac7d8bbb6f42e933",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8e9d4f3f762a40a380b8bcf6f81b3ab0",
              "IPY_MODEL_c164b660385243fd992a04cae29e622e"
            ]
          }
        },
        "c227d8c0bd6b44dbac7d8bbb6f42e933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e9d4f3f762a40a380b8bcf6f81b3ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5990572bd0204c5aa5baa8e1133cf396",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0417d61144ea41ff91d8224c5cb5f61d"
          }
        },
        "c164b660385243fd992a04cae29e622e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8564d545169c46648a8bc59b9890e0bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 636kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_119b0b69327148428ef889de8e1697fa"
          }
        },
        "5990572bd0204c5aa5baa8e1133cf396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0417d61144ea41ff91d8224c5cb5f61d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8564d545169c46648a8bc59b9890e0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "119b0b69327148428ef889de8e1697fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig1HGm_sXvHx"
      },
      "source": [
        "# Passage Retrieval with Bert on CORD-19 dataset \n",
        "## <div> Vassilis Panagakis </div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_tzpCaZK9Ib",
        "outputId": "430872e2-0a46-4f5f-cc74-40ee0a10e2f2"
      },
      "source": [
        "! pip install -U sentence-transformers\r\n",
        "\r\n",
        "import scipy.spatial\r\n",
        "import numpy as np\r\n",
        "import os, json\r\n",
        "import glob\r\n",
        "import re\r\n",
        "import torch\r\n",
        "import pandas as pd\r\n",
        "import transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/e2/84d6acfcee2d83164149778a33b6bdd1a74e1bcb59b2b2cd1b861359b339/sentence-transformers-0.4.1.2.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.8MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.7.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 47.0MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.7.0)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.4.1.2-cp37-none-any.whl size=103068 sha256=e3825873f6cfeaae60ff34b540fd1676f8c495e3a5194b5ab00f5cea2d70ecc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/33/d1/5703dd56199c09d4a1b41e0c07fb4e7765a84d787cbdc48ac3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=e7d83700b1951df12f72757e4a5d90ced99d6c990a7686847a999ea79b7167d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.4.1.2 sentencepiece-0.1.95 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDjMXTVaVscb"
      },
      "source": [
        "# Passage retrieval on CORD-19 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM9WDlaBfSTt"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJGktKinh9b2",
        "outputId": "c6c1fc24-c796-47a3-87f0-bbf15f6140cf"
      },
      "source": [
        "from google.colab import drive \r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJBPyolXe8-H"
      },
      "source": [
        "# get \"/comm_use_subset\" directory path on google drive \r\n",
        "dir_path = 'gdrive/My Drive/Colab Notebooks/comm_use_subset'\r\n",
        "\r\n",
        "json_articles = glob.glob(os.path.join(dir_path, \"*.json\"))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx4MfsQghzUy"
      },
      "source": [
        "## Data Pre-processing\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBYridvBXA3B"
      },
      "source": [
        "**Initial number of articles**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoFNLzdyh2bq",
        "outputId": "01a78ad5-7077-4664-adc1-eaa9a17c884c"
      },
      "source": [
        "len(json_articles)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oLtEBsRLWcR"
      },
      "source": [
        "The cord-19_2020-03-13 version of the Cord-19 dataset contains 9000 articles. \r\n",
        "In order to accelerate the time response of our model we use some keywords such as **RNA virus, SARS, coronavirus, COVID, SARS-Cov-2, 2019-nCoV, vaccine, Antibody-Dependent Enhancement, naproxen, clarithromycin, minocyclinethat** and more to filter the articles. As a result if an article's title doesn't contain any of the keywords, we don't include the article in our database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCBaE8oULUCn"
      },
      "source": [
        "### Cleanse Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuD4qRoTi7_w"
      },
      "source": [
        "if not os.path.exists('gdrive/My Drive/Colab Notebooks/covid19Data.csv'): \r\n",
        "    # cleanse data based on following keywords\r\n",
        "    keywords = ['persistence','decontamination','RNA virus',' SARS','coronavirus', 'COVID', 'SARS-Cov-2', \r\n",
        "                '-CoV', '2019-nCoV','coronavirus vaccine','Antibody-Dependent Enhancement', 'prophylaxis clinical',\r\n",
        "                'asymptomatic', 'symptoms', 'presymptomatic', 'virus', 'MERS', 'contagious illness', \r\n",
        "                'incubation period', 'pathogen', 'patient zero', 'PPE', 'social distancing', 'self-isolation', \r\n",
        "                'self-quarantine', 'medicine', 'super spreader', 'antibody', 'outbreak', 'epidemic', 'pandemic',\r\n",
        "                'mask', 'health professionals', 'N95', 'disease', 'immunity', 'contagious virus', 'COVID-19'] \r\n",
        "\r\n",
        "    # initialize lists to store filtered titles and ids\r\n",
        "    titles = []\r\n",
        "    ids = []\r\n",
        "\r\n",
        "    for json_article in json_articles: # traverse each json article\r\n",
        "        text = json.load(open(json_article))\r\n",
        "\r\n",
        "        # clean title\r\n",
        "        title = text['metadata']['title']  \r\n",
        "        title = re.sub(r'[^\\x00-\\x7F]',' ', title)\r\n",
        "\r\n",
        "        # append article only if it contains any of the keywords in its title\r\n",
        "        if title != '' and any(keyword.lower() in title.lower() for keyword in keywords):\r\n",
        "            titles.append(title)\r\n",
        "            ids.append(text['paper_id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeYgzTGOZ7_o"
      },
      "source": [
        "### Store filtered data to csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vGLIk3hjtrJ"
      },
      "source": [
        "key_df = pd.DataFrame({'title': titles, 'id': ids})\r\n",
        "meta_df = pd.read_csv('gdrive/My Drive/Colab Notebooks/all_sources_metadata_2020-03-13.csv') # load metadata csv file\r\n",
        "\r\n",
        "articles_df = pd.merge(meta_df, key_df)\r\n",
        "articles_df = articles_df.drop_duplicates(subset='title') # remove duplicate articles based on title\r\n",
        "articles_df = articles_df.dropna(subset=['abstract'])     # remove articles with no 'abstract' field\r\n",
        "articles_df = articles_df.reset_index(drop=True)\r\n",
        "\r\n",
        "articles_df.to_csv('gdrive/My Drive/Colab Notebooks/covid19Data.csv', index = False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mwM0CaSdRzb"
      },
      "source": [
        "### Load filtered data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "n2bZo5EXYxe7",
        "outputId": "c6b3254f-70cf-4910-bcc7-b40c1410968f"
      },
      "source": [
        "# load filtered data from csv file\r\n",
        "articles_df = pd.read_csv('gdrive/My Drive/Colab Notebooks/covid19Data.csv')\r\n",
        "\r\n",
        "articles_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sha</th>\n",
              "      <th>source_x</th>\n",
              "      <th>title</th>\n",
              "      <th>doi</th>\n",
              "      <th>pmcid</th>\n",
              "      <th>pubmed_id</th>\n",
              "      <th>license</th>\n",
              "      <th>abstract</th>\n",
              "      <th>publish_time</th>\n",
              "      <th>authors</th>\n",
              "      <th>journal</th>\n",
              "      <th>Microsoft Academic Paper ID</th>\n",
              "      <th>WHO #Covidence</th>\n",
              "      <th>has_full_text</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>e9239100c5493ea914dc23c3d7a262f4326022ac</td>\n",
              "      <td>CZI</td>\n",
              "      <td>Distinct Roles for Sialoside and Protein Recep...</td>\n",
              "      <td>10.1128/mBio.02764-19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cc-by</td>\n",
              "      <td>Coronaviruses (CoVs) are common human and anim...</td>\n",
              "      <td>2020</td>\n",
              "      <td>Qing, Enya; Hantak, Michael; Perlman, Stanley;...</td>\n",
              "      <td>mBio</td>\n",
              "      <td>3.005811e+09</td>\n",
              "      <td>#2427</td>\n",
              "      <td>True</td>\n",
              "      <td>3fa90782b0cd99871663f5317bb69d255cfde50f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c9fee561c2a3834645dbb61dc4ae6448051da492</td>\n",
              "      <td>CZI</td>\n",
              "      <td>Comprehensive Genomic Characterization Analysi...</td>\n",
              "      <td>10.3389/fmicb.2019.03036</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cc-by</td>\n",
              "      <td>Porcine delta coronavirus (PDCoV) is a novel e...</td>\n",
              "      <td>2020</td>\n",
              "      <td>Liui, Junli; Wang, Fangfang; Du, Liuyang; Li, ...</td>\n",
              "      <td>Frontiers in Microbiology</td>\n",
              "      <td>3.003968e+09</td>\n",
              "      <td>#5462</td>\n",
              "      <td>True</td>\n",
              "      <td>c9fee561c2a3834645dbb61dc4ae6448051da492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>655537fc8cc52bccf43cf7189ab060d3097caa7a</td>\n",
              "      <td>CZI</td>\n",
              "      <td>Potential Factors Influencing Repeated SARS Ou...</td>\n",
              "      <td>10.3390/ijerph17051633</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cc-by</td>\n",
              "      <td>Within last 17 years two widespread epidemics ...</td>\n",
              "      <td>2020</td>\n",
              "      <td>Sun, Zhong; Thilakavathy, Karuppiah; Kumar, S....</td>\n",
              "      <td>International Journal of Environmental Researc...</td>\n",
              "      <td>2.615949e+09</td>\n",
              "      <td>#3296</td>\n",
              "      <td>True</td>\n",
              "      <td>655537fc8cc52bccf43cf7189ab060d3097caa7a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>f294f0df7468a8ac9e27776cc15fa20297a9f040</td>\n",
              "      <td>CZI</td>\n",
              "      <td>Systematic Comparison of Two Animal-to-Human T...</td>\n",
              "      <td>10.3390/v12020244</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cc-by</td>\n",
              "      <td>After the outbreak of the severe acute respira...</td>\n",
              "      <td>2020</td>\n",
              "      <td>Xu, Jiabao; Zhao, Shizhe; Teng, Tieshan; Abdal...</td>\n",
              "      <td>Viruses</td>\n",
              "      <td>2.163319e+09</td>\n",
              "      <td>#1449</td>\n",
              "      <td>True</td>\n",
              "      <td>f294f0df7468a8ac9e27776cc15fa20297a9f040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5734e3b81e16fe1976a129c5a0872716f3dd50b8</td>\n",
              "      <td>CZI</td>\n",
              "      <td>A new coronavirus associated with human respir...</td>\n",
              "      <td>10.1038/s41586-020-2008-3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32015508.0</td>\n",
              "      <td>cc-by</td>\n",
              "      <td>Emerging infectious diseases, such as SARS and...</td>\n",
              "      <td>2020</td>\n",
              "      <td>Wu, Fan; Zhao, Su; Yu, Bin; Chen, Yan-Mei; Wan...</td>\n",
              "      <td>Nature</td>\n",
              "      <td>3.003217e+09</td>\n",
              "      <td>#258</td>\n",
              "      <td>True</td>\n",
              "      <td>5734e3b81e16fe1976a129c5a0872716f3dd50b8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        sha  ...                                        id\n",
              "0  e9239100c5493ea914dc23c3d7a262f4326022ac  ...  3fa90782b0cd99871663f5317bb69d255cfde50f\n",
              "1  c9fee561c2a3834645dbb61dc4ae6448051da492  ...  c9fee561c2a3834645dbb61dc4ae6448051da492\n",
              "2  655537fc8cc52bccf43cf7189ab060d3097caa7a  ...  655537fc8cc52bccf43cf7189ab060d3097caa7a\n",
              "3  f294f0df7468a8ac9e27776cc15fa20297a9f040  ...  f294f0df7468a8ac9e27776cc15fa20297a9f040\n",
              "4  5734e3b81e16fe1976a129c5a0872716f3dd50b8  ...  5734e3b81e16fe1976a129c5a0872716f3dd50b8\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYC_FH7rdmiz"
      },
      "source": [
        "**Number of articles after filtering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ePLKfjTa7p",
        "outputId": "18491ffb-8253-4612-f428-09fcf110bddc"
      },
      "source": [
        "titles = articles_df['title'].tolist()\r\n",
        "ids = articles_df['id'].tolist()\r\n",
        "len(titles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3203"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvmieH-WeRXG"
      },
      "source": [
        "## Title Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBdEp9FFnpCV"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\r\n",
        "from datetime import datetime\r\n",
        "\r\n",
        "# function that returns the closest article titles to on a query based on cosine similarity metric\r\n",
        "def k_closest(embedder, question, titles, articles, k):\r\n",
        "    start = datetime.now() # start time counter\r\n",
        "\r\n",
        "    query_embeddings = embedder.encode([question])  # query embeddings\r\n",
        "    title_embeddings = embedder.encode(titles)      # title embeddings\r\n",
        "\r\n",
        "    dist = scipy.spatial.distance.cdist(query_embeddings, title_embeddings, \"cosine\")[0]  # calculate distances based on vosine similarity\r\n",
        "\r\n",
        "    neighbors = zip(range(len(dist)), dist)\r\n",
        "    neighbors = sorted(neighbors, key=lambda x: x[1]) # sort neighbors from highest to lowest cosine similarity\r\n",
        "\r\n",
        "    # initialize neighbors list\r\n",
        "    closest_ids = []\r\n",
        "    closest_titles = []\r\n",
        "    closest_scores = []\r\n",
        "    closest_abstracts = []\r\n",
        "    abstracts = list(articles.abstract)\r\n",
        "\r\n",
        "    for i, dist in neighbors[0:k]:\r\n",
        "        closest_ids.append(ids[i])\r\n",
        "        closest_titles.append(titles[i])\r\n",
        "        closest_scores.append(round((1-dist), 4))\r\n",
        "        closest_abstracts.append(abstracts[i])\r\n",
        "    \r\n",
        "    end = datetime.now()  # end time counter\r\n",
        "\r\n",
        "    time_dif = (end - start).total_seconds() # count time difference in seconds\r\n",
        "\r\n",
        "    print(\"Execution Time: {0:4f} seconds\\n\".format(time_dif))\r\n",
        "\r\n",
        "    closest_df = pd.DataFrame({\r\n",
        "        'id': closest_ids,\r\n",
        "        'cosine_similarity': closest_scores,\r\n",
        "        'title': closest_titles,\r\n",
        "        'abstract': closest_abstracts\r\n",
        "    })\r\n",
        "    \r\n",
        "    return closest_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nf9hH_vqiEJ"
      },
      "source": [
        "### Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt7Az9_ukO-Q",
        "outputId": "631e3fed-6424-4469-a063-58bb57f833d4"
      },
      "source": [
        "# enable gpu for faster execution\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(\"Device available for running: \")\r\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device available for running: \n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pJM6S7fqlQ8"
      },
      "source": [
        "### BERT-base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TbzadMol36s",
        "outputId": "001d4d4d-96ac-4cab-ba52-72e5ba82dc97"
      },
      "source": [
        "sentence_model1 = SentenceTransformer('bert-base-nli-mean-tokens')\r\n",
        "sentence_model1.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:08<00:00, 45.1MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceTransformer(\n",
              "  (0): Transformer(\n",
              "    (auto_model): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): Pooling()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3qn7hUNtnXr"
      },
      "source": [
        "#### Suggested questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "a7Ou7U5Pl39W",
        "outputId": "cd5b621c-fb03-41cd-effa-51b7e7386d04"
      },
      "source": [
        "query1 = 'What are the coronaviruses?'\r\n",
        "\r\n",
        "bbQ1_df = k_closest(sentence_model1, query1, titles, articles_df, 1)\r\n",
        "bbQ1_df[['cosine_similarity', 'title']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Execution Time: 12.332064 seconds\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.8506</td>\n",
              "      <td>Unanswered questions about the Middle East res...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosine_similarity                                              title\n",
              "0             0.8506  Unanswered questions about the Middle East res..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "dtoL-mXzl3__",
        "outputId": "c77f3a54-24e9-48dd-aabe-edb44d8a6cf3"
      },
      "source": [
        "query2 = 'What is Coronavirus Disease 2019?'\r\n",
        "\r\n",
        "bbQ2_df = k_closest(sentence_model1, query2, titles, articles_df, 5)\r\n",
        "bbQ2_df[['cosine_similarity', 'title']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Execution Time: 3.978883 seconds\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.8758</td>\n",
              "      <td>An interim review of the epidemiological chara...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7570</td>\n",
              "      <td>Potential Rapid Diagnostics, Vaccine and Thera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7162</td>\n",
              "      <td>Q&amp;A: The novel coronavirus outbreak causing CO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.6963</td>\n",
              "      <td>Molecular Diagnosis of a Novel Coronavirus (20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6861</td>\n",
              "      <td>Croup Is Associated with the Novel Coronavirus...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosine_similarity                                              title\n",
              "0             0.8758  An interim review of the epidemiological chara...\n",
              "1             0.7570  Potential Rapid Diagnostics, Vaccine and Thera...\n",
              "2             0.7162  Q&A: The novel coronavirus outbreak causing CO...\n",
              "3             0.6963  Molecular Diagnosis of a Novel Coronavirus (20...\n",
              "4             0.6861  Croup Is Associated with the Novel Coronavirus..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "TrU0sPDktsEp",
        "outputId": "903b4846-b3f2-415d-d6d8-cfd9f942d797"
      },
      "source": [
        "query3 = 'What is caused by SARS-COV2?'\r\n",
        "\r\n",
        "bbQ3_df = k_closest(sentence_model1, query3, titles, articles_df, 10)\r\n",
        "bbQ3_df[['cosine_similarity', 'title']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Execution Time: 12.161577 seconds\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7361</td>\n",
              "      <td>Porcine Hemagglutinating Encephalomyelitis Vir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7202</td>\n",
              "      <td>Q&amp;A: What are pathogens, and what have they do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7199</td>\n",
              "      <td>The role of CXCL10 in the pathogenesis of expe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.7151</td>\n",
              "      <td>Antagonizing Interferon-Mediated Immune Respon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7142</td>\n",
              "      <td>Trypsin-independent porcine epidemic diarrhea ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.7086</td>\n",
              "      <td>Sialic Acid Binding Properties of Soluble Coro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7068</td>\n",
              "      <td>Virus-induced ER stress and the unfolded prote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7019</td>\n",
              "      <td>Biochemical Characterization of Middle East Re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.7000</td>\n",
              "      <td>Host Modulators of H1N1 Cytopathogenicity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.6990</td>\n",
              "      <td>HACE1 Negatively Regulates Virus-Triggered Typ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosine_similarity                                              title\n",
              "0             0.7361  Porcine Hemagglutinating Encephalomyelitis Vir...\n",
              "1             0.7202  Q&A: What are pathogens, and what have they do...\n",
              "2             0.7199  The role of CXCL10 in the pathogenesis of expe...\n",
              "3             0.7151  Antagonizing Interferon-Mediated Immune Respon...\n",
              "4             0.7142  Trypsin-independent porcine epidemic diarrhea ...\n",
              "5             0.7086  Sialic Acid Binding Properties of Soluble Coro...\n",
              "6             0.7068  Virus-induced ER stress and the unfolded prote...\n",
              "7             0.7019  Biochemical Characterization of Middle East Re...\n",
              "8             0.7000          Host Modulators of H1N1 Cytopathogenicity\n",
              "9             0.6990  HACE1 Negatively Regulates Virus-Triggered Typ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1awrp77mtsfO"
      },
      "source": [
        "#### Extra questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "ThA89A9SvtMJ",
        "outputId": "f5810a9c-2a97-44b8-b5dd-bc0b4a56a122"
      },
      "source": [
        "query4 = 'What are most common underlying diseases in covid-19 patients?'\r\n",
        "\r\n",
        "bbQ4_df = k_closest(sentence_model1, query4, titles, articles_df, 1)\r\n",
        "bbQ4_df[['cosine_similarity', 'title']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Execution Time: 12.183343 seconds\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7019</td>\n",
              "      <td>A Comparative Study of Clinical Presentation a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosine_similarity                                              title\n",
              "0             0.7019  A Comparative Study of Clinical Presentation a..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "cWS_MiwBvtML",
        "outputId": "b906c332-eba0-4996-dede-209f9815d232"
      },
      "source": [
        "query5 = 'what are the public measures to control the spread of covid-19?'\r\n",
        "\r\n",
        "bbQ5_df = k_closest(sentence_model1, query5, titles, articles_df, 3)\r\n",
        "bbQ5_df[['cosine_similarity', 'title']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Execution Time: 12.258709 seconds\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7171</td>\n",
              "      <td>Including the public in pandemic planning: a d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.6988</td>\n",
              "      <td>Estimated effectiveness of symptom and risk sc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.6944</td>\n",
              "      <td>Q&amp;A: What are pathogens, and what have they do...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosine_similarity                                              title\n",
              "0             0.7171  Including the public in pandemic planning: a d...\n",
              "1             0.6988  Estimated effectiveness of symptom and risk sc...\n",
              "2             0.6944  Q&A: What are pathogens, and what have they do..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjv1uMjtquPw"
      },
      "source": [
        "### DistilBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9lHFFIWl4Cl",
        "outputId": "9848189e-7ada-48dc-89e8-23d7cf9f8a8f"
      },
      "source": [
        "sentence_model2 = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\r\n",
        "sentence_model2.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245M/245M [00:03<00:00, 73.9MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceTransformer(\n",
              "  (0): Transformer(\n",
              "    (auto_model): DistilBertModel(\n",
              "      (embeddings): Embeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (transformer): Transformer(\n",
              "        (layer): ModuleList(\n",
              "          (0): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (1): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (2): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (3): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (4): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (5): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): Pooling()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O60IMg7ctvdy"
      },
      "source": [
        "#### Suggested questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "suwbX1DMl4FP",
        "outputId": "aca6a568-9716-40ba-e6a0-84396fbac1b9"
      },
      "source": [
        "query1 = 'What are the coronaviruses?'\r\n",
        "\r\n",
        "dbQ1_df = k_closest(sentence_model2, query1, titles, articles_df, 1)\r\n",
        "dbQ1_df[['cosine_similarity', 'title']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Execution Time: 3.450956 seconds\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.6567</td>\n",
              "      <td>Genotyping coronaviruses associated with felin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosine_similarity                                              title\n",
              "0             0.6567  Genotyping coronaviruses associated with felin..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "majr4jdSvaD3",
        "outputId": "07811ac4-4e07-48c5-bbd5-ffe016f13b62"
      },
      "source": [
        "query2 = 'What is Coronavirus Disease 2019?'\r\n",
        "\r\n",
        "dbQ2_df = k_closest(sentence_model2, query2, titles, articles_df, 5)\r\n",
        "dbQ2_df[['cosine_similarity', 'title']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Execution Time: 2.100247 seconds\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7681</td>\n",
              "      <td>An interim review of the epidemiological chara...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.6637</td>\n",
              "      <td>Potential Rapid Diagnostics, Vaccine and Thera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.6166</td>\n",
              "      <td>Q&amp;A: The novel coronavirus outbreak causing CO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.5782</td>\n",
              "      <td>Molecular Diagnosis of a Novel Coronavirus (20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.5722</td>\n",
              "      <td>Regulatory T Cells in Arterivirus and Coronavi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosine_similarity                                              title\n",
              "0             0.7681  An interim review of the epidemiological chara...\n",
              "1             0.6637  Potential Rapid Diagnostics, Vaccine and Thera...\n",
              "2             0.6166  Q&A: The novel coronavirus outbreak causing CO...\n",
              "3             0.5782  Molecular Diagnosis of a Novel Coronavirus (20...\n",
              "4             0.5722  Regulatory T Cells in Arterivirus and Coronavi..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "gK1LLuWivaEa",
        "outputId": "85751f6b-366e-4d88-81d0-6feecba430fd"
      },
      "source": [
        "query3 = 'What is caused by SARS-COV2?'\r\n",
        "\r\n",
        "dbQ3_df = k_closest(sentence_model2, query3, titles, articles_df, 10)\r\n",
        "dbQ3_df[['cosine_similarity', 'title']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Execution Time: 3.432332 seconds\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.5973</td>\n",
              "      <td>Surface vimentin is critical for the cell entr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.5943</td>\n",
              "      <td>The Role of Severe Acute Respiratory Syndrome ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5850</td>\n",
              "      <td>SARS-CoV Pathogenesis Is Regulated by a STAT1 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.5805</td>\n",
              "      <td>Analysis of Intraviral Protein-Protein Interac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.5744</td>\n",
              "      <td>The SARS-Unique Domain (SUD) of SARS Coronavir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5524</td>\n",
              "      <td>Genetic lesions within the 3a gene of SARS-CoV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.5468</td>\n",
              "      <td>Identification of Residues of SARS-CoV nsp1 Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.5356</td>\n",
              "      <td>The SARS-Coronavirus-Host Interactome: Identif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.5337</td>\n",
              "      <td>Different residues in the SARS-CoV spike prote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.5223</td>\n",
              "      <td>Inhibition of SARS Pseudovirus Cell Entry by L...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosine_similarity                                              title\n",
              "0             0.5973  Surface vimentin is critical for the cell entr...\n",
              "1             0.5943  The Role of Severe Acute Respiratory Syndrome ...\n",
              "2             0.5850  SARS-CoV Pathogenesis Is Regulated by a STAT1 ...\n",
              "3             0.5805  Analysis of Intraviral Protein-Protein Interac...\n",
              "4             0.5744  The SARS-Unique Domain (SUD) of SARS Coronavir...\n",
              "5             0.5524     Genetic lesions within the 3a gene of SARS-CoV\n",
              "6             0.5468  Identification of Residues of SARS-CoV nsp1 Th...\n",
              "7             0.5356  The SARS-Coronavirus-Host Interactome: Identif...\n",
              "8             0.5337  Different residues in the SARS-CoV spike prote...\n",
              "9             0.5223  Inhibition of SARS Pseudovirus Cell Entry by L..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wiNpP4Jtwp5"
      },
      "source": [
        "#### Extra questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "HaS5CGJewm_g",
        "outputId": "525a96d2-88ec-4d08-ca6f-512673064466"
      },
      "source": [
        "query4 = 'What are most common underlying diseases in covid-19 patients?'\r\n",
        "\r\n",
        "dbQ4_df = k_closest(sentence_model2, query4, titles, articles_df, 1)\r\n",
        "dbQ4_df[['cosine_similarity', 'title']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Execution Time: 3.407676 seconds\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.657</td>\n",
              "      <td>Q&amp;A: The novel coronavirus outbreak causing CO...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosine_similarity                                              title\n",
              "0              0.657  Q&A: The novel coronavirus outbreak causing CO..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "4k3arrwowm_9",
        "outputId": "12561a0d-2459-4338-a191-152af972b277"
      },
      "source": [
        "query5 = 'what are the public measures to control the spread of covid-19?'\r\n",
        "\r\n",
        "dbQ5_df = k_closest(sentence_model2, query5, titles, articles_df, 3)\r\n",
        "dbQ5_df[['cosine_similarity', 'title']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Execution Time: 3.402274 seconds\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.6664</td>\n",
              "      <td>Estimated effectiveness of symptom and risk sc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.5969</td>\n",
              "      <td>Identification of COVID-19 Can be Quicker thro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5772</td>\n",
              "      <td>Q&amp;A: The novel coronavirus outbreak causing CO...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosine_similarity                                              title\n",
              "0             0.6664  Estimated effectiveness of symptom and risk sc...\n",
              "1             0.5969  Identification of COVID-19 Can be Quicker thro...\n",
              "2             0.5772  Q&A: The novel coronavirus outbreak causing CO..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi77biDsq5UJ"
      },
      "source": [
        "### BERT base vs DistilBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UATIUs58lp7"
      },
      "source": [
        "**As we know the initial BERT models are enormous, as they contain a big number of layers and connections. It is obvious, that they are not energy-efficient and they require costly GPU servers to serve at scale. So it is difficult to put these kind of models in massive production. As a result, at some point there was a need of upgraded BERT models of smaller sizes. Through the passage of years many techniques were used to deal with this problem. The most significant of them are quantization, where network weights are approximated with a smaller precision and weights pruning, where some network's connections are removed.**\r\n",
        "\r\n",
        "**In our current homework we apply another important technique, distillation. Distillation is a compression technique, in which a small model is trained to reproduce the behavior of a larger model. In this technique, a student network (DistilBERT) is trained to mimic the full output distribution of the teacher network (BERT-base). In particular, DistilBERT is a small version of BERT, in which the token-type embeddings and the pooler are removed. The rest of the architecture is identical, while the number of layers is reduced by a factor of two. As we know from theory, DistilBERT has about half the total number of parameters of BERT base and it is more than 60% faster than BERT, in terms of inference time. For the above reasons, we compare the `bert-base-nli-mean-tokens` sentence transformer with the `distilbert-base-nli-stsb-mean-tokens` sentence transformer, in order to investigate the cosine similarity score - time execution trade-off between the two models.**\r\n",
        "\r\n",
        "**We experiment with the same 5 queries on both our models. At each execution we ask for a different number of k closest articles' titles, in order to study the different scores and times range. After executing all the queries we observe a clear contradiction between the two models. It is obvious, that the cosine similarity scores of our first BERT-base model are significantly higher than the respective scores of our second DistilBERT model (more than 15% in a query to query comparison). Of course, the articles' titles that each model returns are not identical or in the same priority but we can notice the same articles' titles in some cases, as well. On the other hand, the execution times of the DistilBERT model are usually less than half to the relative BERT-base times. Moreover, as expected, when we raise the number k of expected titles the execution times rise accordingly. We also notice that the execution times are relatively fast because of the reduced database we use, aftering filtering the articles. To sum up, the theoretical knowledge that we presented on the previous paragraphs is verified via our experiments. Essentially, the DistilBERT model leads to faster but uncertain predictions, due to its reduced layers and parametres, while the dense BERT-base model produces highly accurate but slower results. Obviously, there are plenty more criteria that can be used to compare such complicated models, but score metrics and time execution are the ones that must definitely be mentioned.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBvjtfcHbFWZ"
      },
      "source": [
        "## Passage Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKVvJQRp3LrL",
        "outputId": "03c437a5-1abc-40b4-acdc-00d72bc2b4d3"
      },
      "source": [
        "!pip install colorama\r\n",
        "\r\n",
        "import colorama\r\n",
        "import re \r\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oCDlUDQJPUon"
      },
      "source": [
        "# function that gets a question and an article's body text \n",
        "# and returns the article's passage that answers the given question and its score\n",
        "def retrieve_passage(model, tokenizer, question, text):\n",
        "    # tokenize combined question and text string\n",
        "    input_ids = tokenizer.encode(question, text)\n",
        "\n",
        "    sep_ind = input_ids.index(tokenizer.sep_token_id) # get index of first [SEP] token\n",
        "\n",
        "    segA_toks = sep_ind + 1 # segment A tokens + [SEP] token \n",
        "    segB_toks = len(input_ids) - segA_toks # segment B tokens\n",
        "\n",
        "    seg_ids = [0]*segA_toks + [1]*segB_toks # construct the list of 0s and 1s\n",
        "    assert len(seg_ids) == len(input_ids) # every input token must have a segment id\n",
        "    \n",
        "    # insert embeddings to the model\n",
        "    if len(seg_ids) < 512:\n",
        "      start_scores, end_scores = model(torch.tensor([input_ids]).to(device), \n",
        "                                       token_type_ids=torch.tensor([seg_ids]).to(device), return_dict=False)\n",
        "    else:\n",
        "        start_scores, end_scores = model(torch.tensor([input_ids[:512]]).to(device), \n",
        "                                         token_type_ids=torch.tensor([seg_ids[:512]]).to(device), return_dict=False)\n",
        "        \n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids) # get tokens based on ids\n",
        "\n",
        "    # get the start token and end token indicies \n",
        "    start_tok_ind = torch.argmax(start_scores)\n",
        "    end_tok_ind = torch.argmax(end_scores)\n",
        "    \n",
        "    if start_tok_ind <= 0 or end_tok_ind <= 0 or end_tok_ind <= start_tok_ind:\n",
        "        answer = \"None\"\n",
        "        score = -99999.0\n",
        "    \n",
        "    else:\n",
        "        answer = tokens[start_tok_ind]  # answer's first token is the start token\n",
        "\n",
        "        for i in range(start_tok_ind + 1, end_tok_ind + 1): # traverse the rest of the tokens\n",
        "\n",
        "            # if it is a subword token, construct the whole token\n",
        "            if tokens[i][0:2] == '##':\n",
        "                answer += tokens[i][2:]\n",
        "\n",
        "            # else add token to the answer after a whitespace\n",
        "            else:\n",
        "                answer += ' ' + tokens[i]\n",
        "\n",
        "        # remove [CLS] and [SEP] tokens\n",
        "        answer = answer.replace('[CLS]', '')\n",
        "        answer = answer.replace('[SEP]', '').strip()\n",
        "\n",
        "        # define score as the average value of the best start and end tokens\n",
        "        score = (start_scores.max() + end_scores.max()) / 2\n",
        "        score = score.item()\n",
        "\n",
        "    return answer, score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nNKyhf4YPUow"
      },
      "source": [
        "# function that gets a question and all articles' body texts \n",
        "# and returns the best passage of each article that answers the given question and its score\n",
        "def retrieve_all_passages(model, tokenizer, question, abstracts):\n",
        "    total_answers = []\n",
        "    total_scores = []\n",
        "\n",
        "    for i, abstract in enumerate(abstracts):  # get best answer-passage from each article\n",
        "        answer, score = retrieve_passage(model, tokenizer, question, abstract)\n",
        "        total_answers.append(answer)\n",
        "        total_scores.append(score)\n",
        "\n",
        "    return total_answers, total_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZIyG9TlcPUow"
      },
      "source": [
        "# function that displays the passage of each one of k articles than answers a given question\n",
        "def display_passages(question, articles, answers, scores, best_indices, k):\n",
        "    print(\"\\n*** The answer-passage is highlighted with red color in the abstract text of each article ***\\n\")\n",
        "    print(\"Question: \" + question)\n",
        "    print()\n",
        "\n",
        "    for i, ind in enumerate(best_indices):\n",
        "        article = articles.iloc[ind] # get article in ind position\n",
        "        \n",
        "        print(\"Title: \" + article['title'])\n",
        "        print(\"Score: \" + str(scores[ind]))\n",
        "        \n",
        "        abstract = article['abstract']\n",
        "        \n",
        "        # cleanse the passage\n",
        "        passage = answers[ind]\n",
        "        passage = re.sub(' -', '-', passage)\n",
        "        passage = re.sub('- ', '-', passage)\n",
        "        passage = re.sub(' ,', ',', passage)\n",
        "        passage = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', passage)\n",
        "        passage = re.sub('\\( ', '(', passage)\n",
        "        passage = re.sub(' \\)', ')', passage)\n",
        "        \n",
        "        ins_passage = re.compile(re.escape(passage), re.IGNORECASE)\n",
        "        new_abstract = ins_passage.sub('\\033[31m' + passage + '\\033[39m', abstract) # change passage's color to red\n",
        "        print(\"Abstract: \" + new_abstract)\n",
        "        print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00MQjSXorzuY"
      },
      "source": [
        "### DistilBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3aa40b7fda134e11a09a94a0106d59c1",
            "63c2ff14e99f400aa69a6cdae6dea58d",
            "0716d94ae25a4ee18d609c76570b64c4",
            "80f60742dbb04977b269ebf565bc1597",
            "173b7aa887c04e9098891c7db83865ad",
            "2199ce3aaa3b4618a3dd77f9dc2d23e8",
            "15f52fc47ded4417a48354878a040396",
            "f1131ea44b9a41e8bec401eeb0afa7a9",
            "803ad22e467942f7b1e6dfdc78a1f5fc",
            "385320cf139849db9396528bbaf7b146",
            "ea69f8ce5f024a5ca5cdaed7a8b3669f",
            "a39dd28b75914bf589e4ae086d14d812",
            "7af47f79666f4c919fabf9aa61a993e9",
            "62c2028372ce4b4da18fbde2eac6df98",
            "06921d19457d4408bbd2ea82040e8d32",
            "b9af2971c6b14556930dddb0afd45e08"
          ]
        },
        "id": "1qlcuTszrpPc",
        "outputId": "e55b0234-eb2a-4847-d6a3-f1834c003668"
      },
      "source": [
        "model0 = BertForQuestionAnswering.from_pretrained('distilbert-base-uncased')\r\n",
        "model0.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3aa40b7fda134e11a09a94a0106d59c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "803ad22e467942f7b1e6dfdc78a1f5fc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertForQuestionAnswering: ['distilbert.embeddings.word_embeddings.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "ee7633f7e5804b3299a6bf0fcdf13da2",
            "ccf203d3926844feb53d16ec50ba1872",
            "a2705782a1bf428496079556ed3fe17e",
            "7b6ba9d4c4d14270acae5796c4f8d24f",
            "a54855d6151a43bf9c783f75b0a94b37",
            "ad9581fd96e54b02920a94bbf88f3834",
            "d404ba03ca044cf3b0b6fe06f616dc70",
            "f5f0d38b7eb44d67966f33967c4fbe52",
            "fc79ee944c5442289ed33275bcdba802",
            "cb3874ff991d4954bd46a4bdbb571add",
            "c4ec60ce203f4e8099896b73f143d3a2",
            "0392a76e9cf24bbdb79b3081040265a6",
            "57c09b4595814bb899aef7a7e790d669",
            "0ca6595fa8b84aa4875974048c2fdfe0",
            "9546bbb257d949a5a19adb52c52bfb6a",
            "43d6bc60eb0048a7a460ba5994cef43d",
            "89a4232131d24ba4ad0a62d48837378a",
            "a344484697d14f70bc57babe2daa058d",
            "8ef453aa697d4feab603a72ca1a2d58c",
            "285a45b82d154f11ae3fdab3cf9a6fc3",
            "0920ca190ca7428888c18e11a169e86c",
            "1e43f9e761904716ae4f3907508ae8c0",
            "276ce04d482942759c29fb2bb9bc1744",
            "f3538333f3f04b23a8a3e5180738509b"
          ]
        },
        "id": "xQZE-pVSrpQB",
        "outputId": "25c6889c-3a73-499e-b306-87b745863f43"
      },
      "source": [
        "tokenizer0 = BertTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee7633f7e5804b3299a6bf0fcdf13da2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc79ee944c5442289ed33275bcdba802",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89a4232131d24ba4ad0a62d48837378a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmOHGmMfsWIP",
        "outputId": "1b3c4a3f-dc7e-4bcf-c510-4aa494721265"
      },
      "source": [
        "query1 = 'What are the coronaviruses?'\r\n",
        "\r\n",
        "q0_answers, q0_scores = retrieve_all_passages(model0, tokenizer0, query1, articles_df.abstract)\r\n",
        "q0_best_indices = [i[0] for i in sorted(enumerate(q0_scores), key=lambda x:-x[1])]\r\n",
        "\r\n",
        "display_passages(query1, articles_df, q0_answers, q0_scores, q0_best_indices[:1], 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** The answer-passage is highlighted with red color in the abstract text of each article ***\n",
            "\n",
            "Question: What are the coronaviruses?\n",
            "\n",
            "Title: Identifying Live Bird Markets with the Potential to Act as Reservoirs of Avian Influenza A (H5N1) Virus: A Survey in Northern Viet Nam and Cambodia\n",
            "Score: 1.3374799489974976\n",
            "Abstract: Wet markets are common in many parts of the world and may promote the emergence, spread and maintenance of livestock pathogens, including zoonoses. A survey was conducted in order to assess the potential of Vietnamese and Cambodian live bird markets (LBMs) to sustain circulation of highly pathogenic avian influenza virus subtype H5N1 (HPAIV H5N1). Thirty Vietnamese and 8 Cambodian LBMs were visited, and structured interviews were conducted with the market managers and 561 Vietnamese and 84 Cambodian traders. Multivariate and cluster analysis were used to construct a typology of traders based on their poultry management practices\u001b[31m. as a result of those practices and large poultry surplus (unsold poultry reoffered for sale the following day), some poultry traders were shown to promote conditions favorable for perpetuating hpaiv h5n1 in lb\u001b[39mMs. More than 80% of these traders operated in LBMs located in the most densely populated areas, Ha Noi and Phnom Penh. The profiles of sellers operating at a given LBM could be reliably predicted using basic information about the location and type of market. Consequently, LBMs with the largest combination of risk factors for becoming virus reservoirs could be easily identified, potentially allowing control strategies to be appropriately targeted. These findings are of particular relevance to resource-scarce settings with extensively developed LBM systems, commonly found in South-East Asia.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd8Ldfu0trjX"
      },
      "source": [
        "**In order to complete our previous task, the titles retrieval, we experimented with 2 pretrained models, both of which use mean tokens values (`bert-base-nli-mean-tokens`, `distilbert-base-nli-stsb-mean-tokens`). However, there is no option to load this kind of models in a BERT tokenizer, which is needed for our next task, questionanswering. That's why in our first effort to build a QA BERT model we use a similar pretrained model, `distilbert-base-uncased`. As we mentioned before DistilBERT is a small version of BERT, in which the token-type embeddings and the pooler are removed and its parameters are half of BERT-base ones making the model's inference time more than 60% faster compared to the corresponding inference time of BERT.**\r\n",
        "\r\n",
        "**That's the main reason that lead us to use DistilBERT is our first experiment. Time is a significant factor because of the big number of articles that must be checked for the model to find the best passage that answers each question, even though we have already filtered out some of the articles. For our first experiment we posed the model our primary question, namely 'What are the coronaviruses?'. Although the model's response time was ,indeed, fast the outcome was very disappointing. In fact, the outcome was so disappointing that the model didn't even return an answer to the question. As you can see in the above code block there isn't any highlighted sentence in the article's body text (abstract). If anything the returned article seems irrelevant itself, judging from the title, that refers to Live Bird Markets. To be honest, we could anticipate a bad outcome by just noticing the model's produced score value for the specific question, which is just 1.3374. The score is calculated as the average value of the best start and end tokens and as we will see below it gets a value of around 8 in our best experiments. To sum up, DistilBERT model seems unable to deal with a complicated task like questionanswering, due to the lacking number of data on which it is trained. So we have to seek for a more complex model, in order to achieve more satisfying results.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqRA7mZRpjUu"
      },
      "source": [
        "### BERT-large-uncased + finetuned SQuAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjTJF4EJhIRZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "93aa42fa5d5344abad1add36c43c2d4b",
            "696477a3b5b94005aa00a30e6478c60e",
            "4e54869cec9a461ca6ebaca705267c8e",
            "b5f09093779a42d0be0cacdb07733021",
            "783c82e8a35d4de7825f8bd72346ef0c",
            "118f5de11b0e431ea523742c1ad65041",
            "3279c562a5064831b9fecdfc45c1505e",
            "f8234f20035e48b98fda65461a24c98f",
            "0cedcc8af0a04b50a2854d5275319510",
            "70c808952a044f098f8fd3728f0f5e13",
            "7609b415a0cf4223b55041a201635775",
            "2e0598e7fd964c769c6b3cd6e122dacc",
            "1ace10325e284e5e8bbe7f493b3a383a",
            "3edcb8a88346434a92f45e9c05188767",
            "003af04543644465b52f9b2298729bf7",
            "a81cc0e0bd944364baa212841b5cb625"
          ]
        },
        "outputId": "9ade0bc3-e14a-469d-dcb2-de5356f7cc76"
      },
      "source": [
        "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\r\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93aa42fa5d5344abad1add36c43c2d4b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=443.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cedcc8af0a04b50a2854d5275319510",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1340675298.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeUsS5SLl4Kg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "642d1cb8685f4c3893a802cd3eb0939c",
            "c227d8c0bd6b44dbac7d8bbb6f42e933",
            "8e9d4f3f762a40a380b8bcf6f81b3ab0",
            "c164b660385243fd992a04cae29e622e",
            "5990572bd0204c5aa5baa8e1133cf396",
            "0417d61144ea41ff91d8224c5cb5f61d",
            "8564d545169c46648a8bc59b9890e0bc",
            "119b0b69327148428ef889de8e1697fa"
          ]
        },
        "outputId": "5517a4f9-d650-46bc-8b13-1d311327876c"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "642d1cb8685f4c3893a802cd3eb0939c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09Jm8FwqrZHz"
      },
      "source": [
        "#### Suggested questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiUhuWbWe521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ff53df-693d-4569-e740-536cf965c686"
      },
      "source": [
        "query1 = 'What are the coronaviruses?'\r\n",
        "\r\n",
        "q1_answers, q1_scores = retrieve_all_passages(model, tokenizer, query1, articles_df.abstract)\r\n",
        "q1_best_indices = [i[0] for i in sorted(enumerate(q1_scores), key=lambda x:-x[1])]\r\n",
        "\r\n",
        "display_passages(query1, articles_df, q1_answers, q1_scores, q1_best_indices[:1], 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** The answer-passage is highlighted with red color in the abstract text of each article ***\n",
            "\n",
            "Question: What are the coronaviruses?\n",
            "\n",
            "Title: Infectious Bronchitis Virus Nonstructural Protein 4 Alone Induces Membrane Pairing\n",
            "Score: 8.640386581420898\n",
            "Abstract: \u001b[31mpositive-strand rna viruses\u001b[39m, such as coronaviruses, induce cellular membrane rearrangements during replication to form replication organelles allowing for efficient viral RNA synthesis. Infectious bronchitis virus (IBV), a pathogenic avian Gammacoronavirus of significant importance to the global poultry industry, has been shown to induce the formation of double membrane vesicles (DMVs), zippered endoplasmic reticulum (zER) and tethered vesicles, known as spherules. These membrane rearrangements are virally induced; however, it remains unclear which viral proteins are responsible. In this study, membrane rearrangements induced when expressing viral non-structural proteins (nsps) from two different strains of IBV were compared. Three non-structural transmembrane proteins, nsp3, nsp4, and nsp6, were expressed in cells singularly or in combination and the effects on cellular membranes investigated using electron microscopy and electron tomography. In contrast to previously studied coronaviruses, IBV nsp4 alone is necessary and sufficient to induce membrane pairing; however, expression of the transmembrane proteins together was not sufficient to fully recapitulate DMVs. This indicates that although nsp4 is able to singularly induce membrane pairing, further viral or host factors are required in order to fully assemble IBV replicative structures. This study highlights further differences in the mechanism of membrane rearrangements between members of the coronavirus family.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qE4FmQ_tT3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8804edbc-d7f8-4846-e7a0-f02788ed0ea7"
      },
      "source": [
        "query2 = 'What is Coronavirus Disease 2019?'\r\n",
        "\r\n",
        "q2_answers, q2_scores = retrieve_all_passages(model, tokenizer, query2, articles_df.abstract)\r\n",
        "q2_best_indices = [i[0] for i in sorted(enumerate(q2_scores), key=lambda x:-x[1])]\r\n",
        "\r\n",
        "display_passages(query2, articles_df, q2_answers, q2_scores, q2_best_indices[:5], 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** The answer-passage is highlighted with red color in the abstract text of each article ***\n",
            "\n",
            "Question: What is Coronavirus Disease 2019?\n",
            "\n",
            "Title: Genetic manipulation of porcine deltacoronavirus reveals insights into NS6 and NS7 functions: a novel strategy for vaccine design\n",
            "Score: 8.00501823425293\n",
            "Abstract: Porcine deltacoronavirus (PDCoV) is an emerging swine coronavirus that causes \u001b[31msevere diarrhea\u001b[39m, resulting in high mortality in neonatal piglets. Despite widespread outbreaks in many countries, no effective PDCoV vaccines are currently available. Here, we generated, for the first time, a full-length infectious cDNA clone of PDCoV. We further manipulated the infectious clone by replacing the NS6 gene with a green fluorescent protein (GFP) to generate rPDCoV-ΔNS6-GFP; likewise, rPDCoV-ΔNS7 was constructed by removing the ATG start codons of the NS7 gene. Growth kinetics studies suggest that rPDCoV-ΔNS7 could replicate similarly to that of the wild-type PDCoV, whereas rPDCoV-ΔNS6-GFP exhibited a substantial reduction of viral titer in vitro and in vivo. Piglets inoculated with rPDCoV-ΔNS7 or wild-type PDCoV showed similar diarrheic scores and pathological injury. In contrast, rPDCoV-ΔNS6-GFP-infected piglets did not show any clinical signs, indicating that the NS6 protein is an important virulence factor of PDCoV and that the NS6-deficient mutant virus might be a promising live-attenuated vaccine candidate. Taken together, the reverse genetics platform described here not only provides more insights into the role of PDCoV accessory proteins in viral replication and pathogenesis, but also allows the development of novel vaccines against PDCoV infection.\n",
            "\n",
            "\n",
            "Title: Endocytic Pathway of Feline Coronavirus for Cell Entry: Differences in Serotype-Dependent Viral Entry Pathway\n",
            "Score: 7.86771297454834\n",
            "Abstract: Feline coronavirus (FCoV) is a pathogen causing a lethal infectious disease in cats, \u001b[31mfeline infectious peritonitis\u001b[39m. It has two serotypes (type I FCoV and type II FCoV). According to our previous study, type I FCoV infection is inhibited by compounds inducing intracellular cholesterol accumulation, whereas type II FCoV infection is not inhibited. Intracellular cholesterol accumulation was reported to disrupt late endosome function. Based on these findings, types I and II FCoV are considered to enter the cytosol through late and early endosomes, respectively. We investigated whether the antiviral activities of a late endosome trafficking inhibitor and cholesterol-accumulating agents are different between the FCoV serotypes. The late endosome trafficking inhibitor did not inhibit type II FCoV infection, but it inhibited type I FCoV infection. Type I FCoV infection was inhibited by cholesterol-accumulating triazoles, but not by non-cholesterol-accumulating triazoles. These phenomena were observed in both feline cell lines and feline primary macrophages. This study provides additional information on the differences in intracellular reproductive cycle between type I and type II FCoV.\n",
            "\n",
            "\n",
            "Title: Transmissible gastroenteritis virus infection decreases arginine uptake by downregulating CAT-1 expression\n",
            "Score: 7.830136299133301\n",
            "Abstract: Transmissible gastroenteritis virus (TGEV) is a coronavirus that causes \u001b[31msevere diarrhea\u001b[39m in suckling piglets. TGEV primarily targets and infects porcine intestinal epithelial cells, which play an important role in nutrient absorption. However, the effects of TGEV infection on nutrient absorption in swine have not yet been investigated. In this study, we evaluated the impact of TGEV infection on arginine uptake using the porcine small intestinal epithelial cell line IPEC-J2 as a model system. High performance liquid chromatography (HPLC) analyses showed that TGEV infection leads to reduced arginine uptake at 48 hours post-infection (hpi). Expression of cationic amino acid transporter 1 (CAT-1) was attenuated as well. TGEV infection induced activation of phospho-protein kinase C α (p-PKC α), phospho-epidermal growth factor receptor (p-EGFR), and enhanced the expression of caveolin-1, all of which appear to be involved in down-regulating arginine uptake and CAT-1 expression. These results illuminate the relationship between TGEV infection and nutrient absorption, and further our understanding of the mechanisms of TGEV infection.\n",
            "\n",
            "\n",
            "Title: The Nucleocapsid Protein of Human Coronavirus NL63\n",
            "Score: 7.805429458618164\n",
            "Abstract: Human coronavirus (HCoV) NL63 was first described in 2004 and is associated with \u001b[31mrespiratory tract disease\u001b[39m of varying severity. At the genetic and structural level, HCoV-NL63 is similar to other members of the Coronavirinae subfamily, especially human coronavirus 229E (HCoV-229E). Detailed analysis, however, reveals several unique features of the pathogen. The coronaviral nucleocapsid protein is abundantly present in infected cells. It is a multi-domain, multi-functional protein important for viral replication and a number of cellular processes. The aim of the present study was to characterize the HCoV-NL63 nucleocapsid protein. Biochemical analyses revealed that the protein shares characteristics with homologous proteins encoded in other coronaviral genomes, with the N-terminal domain responsible for nucleic acid binding and the C-terminal domain involved in protein oligomerization. Surprisingly, analysis of the subcellular localization of the N protein of HCoV-NL63 revealed that, differently than homologous proteins from other coronaviral species except for SARS-CoV, it is not present in the nucleus of infected or transfected cells. Furthermore, no significant alteration in cell cycle progression in cells expressing the protein was observed. This is in stark contrast with results obtained for other coronaviruses, except for the SARS-CoV.\n",
            "\n",
            "\n",
            "Title: Engineering a Novel Antibody-Peptide Bispecific Fusion Protein Against MERS-CoV\n",
            "Score: 7.803624153137207\n",
            "Abstract: In recent years, tremendous efforts have been made in the engineering of bispecific or multi-specific antibody-based therapeutics by combining two or more functional antigen-recognizing elements into a single construct. However, to the best of our knowledge there has been no reported cases of effective antiviral antibody-peptide bispecific fusion proteins. We previously developed potent fully human monoclonal antibodies and inhibitory peptides against Middle East Respiratory Syndrome Coronavirus (MERS-CoV), a novel coronavirus that causes \u001b[31msevere acute respiratory illness with high mortality\u001b[39m. Here, we describe the generation of antibody-peptide bispecific fusion proteins, each of which contains an anti-MERS-CoV single-chain antibody m336 (or normal human IgG1 CH3 domain as a control) linked with, or without, a MERS-CoV fusion inhibitory peptide HR2P. We found that one of these fusion proteins, designated as m336 diabody-pep, exhibited more potent inhibitory activity than the antibody or the peptide alone against pseudotyped MERS-CoV infection and MERS-CoV S protein-mediated cell-cell fusion, suggesting its potential to be developed as an effective bispecific immunotherapeutic for clinical use.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i1BqNvpqKs8",
        "outputId": "4202dab0-a83a-46ef-fe6c-e2b5f70ee3cd"
      },
      "source": [
        "query3 = 'What is caused by SARS-COV2?'\r\n",
        "\r\n",
        "q3_answers, q3_scores = retrieve_all_passages(model, tokenizer, query3, articles_df.abstract)\r\n",
        "q3_best_indices = [i[0] for i in sorted(enumerate(q3_scores), key=lambda x:-x[1])]\r\n",
        "\r\n",
        "display_passages(query3, articles_df, q3_answers, q3_scores, q3_best_indices[:10], 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** The answer-passage is highlighted with red color in the abstract text of each article ***\n",
            "\n",
            "Question: What is caused by SARS-COV2?\n",
            "\n",
            "Title: The Disulfide Bonds in Glycoprotein E2 of Hepatitis C Virus Reveal the Tertiary Organization of the Molecule\n",
            "Score: 7.8293867111206055\n",
            "Abstract: Hepatitis C virus (HCV), a major cause of \u001b[31mchronic liver disease\u001b[39m in humans, is the focus of intense research efforts worldwide. Yet structural data on the viral envelope glycoproteins E1 and E2 are scarce, in spite of their essential role in the viral life cycle. To obtain more information, we developed an efficient production system of recombinant E2 ectodomain (E2e), truncated immediately upstream its trans-membrane (TM) region, using Drosophila melanogaster cells. This system yields a majority of monomeric protein, which can be readily separated chromatographically from contaminating disulfide-linked aggregates. The isolated monomeric E2e reacts with a number of conformation-sensitive monoclonal antibodies, binds the soluble CD81 large external loop and efficiently inhibits infection of Huh7.5 cells by infectious HCV particles (HCVcc) in a dose-dependent manner, suggesting that it adopts a native conformation. These properties of E2e led us to experimentally determine the connectivity of its 9 disulfide bonds, which are strictly conserved across HCV genotypes. Furthermore, circular dichroism combined with infrared spectroscopy analyses revealed the secondary structure contents of E2e, indicating in particular about 28% β-sheet, in agreement with the consensus secondary structure predictions. The disulfide connectivity pattern, together with data on the CD81 binding site and reported E2 deletion mutants, enabled the threading of the E2e polypeptide chain onto the structural template of class II fusion proteins of related flavi- and alphaviruses. The resulting model of the tertiary organization of E2 gives key information on the antigenicity determinants of the virus, maps the receptor binding site to the interface of domains I and III, and provides insight into the nature of a putative fusogenic conformational change.\n",
            "\n",
            "\n",
            "Title: The Serological and Virological Investigation of Canine Adenovirus Infection on the Dogs\n",
            "Score: 7.797970294952393\n",
            "Abstract: Two types of Canine Adenovirus (CAVs), Canine Adenovirus type 1 (CAV-1), the virus which causes infectious canine hepatitis, and Canine Adenovirus type 2 (CAV-2), which causes \u001b[31mcanine infectious laryngotracheitis\u001b[39m, have been found in dogs. In this study, blood samples taken from 111 dogs, which were admitted to the Internal Medicine Clinic of Selcuk University, Faculty of Veterinary Medicine, with clinical symptoms. Seventy-seven dogs were sampled from Isparta and Burdur dog shelters by random sampling, regardless of the clinical findings. Dogs showed a systemic disease, characterized by fever, diarrhea, vomiting, oculonasal discharge, conjunctivitis, severe moist cough, signs of pulmonary disease and dehydration. Two dogs had corneal opacity and photophobia. In serological studies, 188 serum samples were investigated on the presence of CAV antibodies by ELISA. Total 103 (103/188–54.7%) blood samples were detected to be positive for CAV antibodies by ELISA. However, 85 (85/188–45.2%) blood samples were negative. Blood leukocyte samples from dogs were processed and inoculated onto confluent monolayers of MDCK cells using standard virological techniques. After third passage, cells were examined by direct immunoflourescence test for virus isolation. But positive result was not detected. In conclusion, this study clearly demonstrates the high prevalence of CAV infection in dogs.\n",
            "\n",
            "\n",
            "Title: Survival of the Enveloped Virus Phi6 in Droplets as a Function of Relative Humidity, Absolute Humidity, and Temperature\n",
            "Score: 7.68337345123291\n",
            "Abstract: Infectious diseases caused by enveloped viruses, such as influenza, \u001b[31msevere acute respiratory syndrome\u001b[39m (SARS), and Middle East respiratory syndrome (MERS), cause thousands of deaths and billions of dollars of economic losses per year. Studies have found a relationship among temperature, humidity, and influenza virus incidence, transmission, or survival; however, there are contradictory claims about whether absolute humidity (AH) or relative humidity (RH) is most important in mediating virus infectivity. Using the enveloped bacteriophage Phi6, which has been suggested as a surrogate for influenza viruses and coronaviruses, we designed a study to discern whether AH, RH, or temperature is a better predictor of virus survival in droplets. Our results show that Phi6 survived best at high (>85%) and low (<60%) RHs, with a significant decrease in infectivity at mid-range RHs (∼60 to 85%). At an AH of less than 22 g · m(−3), the loss in infectivity was less than 2 orders of magnitude; however, when the AH was greater than 22 g · m(−3), the loss in infectivity was typically greater than 6 orders of magnitude. At a fixed RH of 75%, infectivity was very sensitive to temperature, decreasing two orders of magnitude between 19°C and 25°C. We used random forest modeling to identify the best environmental predictors for modulating virus infectivity. The model explained 83% of variation in Phi6 infectivity and suggested that RH is the most important factor in controlling virus infectivity in droplets. This research provides novel information about the complex interplay between temperature, humidity, and the survival of viruses in droplets. IMPORTANCE Enveloped viruses are responsible for a number of infectious diseases resulting in thousands of deaths and billions of dollars of economic losses per year in the United States. There has been a lively debate in the literature over whether absolute humidity (AH) or relative humidity (RH) modulates virus infectivity. We designed a controlled study and used advanced statistical modeling techniques specifically to address this question. By providing an improved understanding of the relationship between environmental conditions and virus infectivity, our work will ultimately lead to improved strategies for predicting and controlling disease transmission.\n",
            "\n",
            "\n",
            "Title: Aptamers in Diagnostics and Treatment of Viral Infections\n",
            "Score: 7.4373064041137695\n",
            "Abstract: Aptamers are in vitro selected DNA or RNA molecules that are capable of binding a wide range of nucleic and non-nucleic acid molecules with high affinity and specificity. They have been conducted through the process known as SELEX (Systematic Evolution of Ligands by Exponential Enrichment). It serves to reach specificity and considerable affinity to target molecules, including those of viral origin, both proteins and nucleic acids. Properties of aptamers allow detecting virus infected cells or viruses themselves and make them competitive to monoclonal antibodies. Specific aptamers can be used to interfere in each stage of the viral replication cycle and also inhibit its penetration into cells. Many current studies have reported possible application of aptamers as a treatment or diagnostic tool in viral infections, e.g., HIV (Human Immunodeficiency Virus), HBV (Hepatitis B Virus), HCV (Hepatitis C Virus), SARS (\u001b[31msevere acute respiratory syndrome\u001b[39m), H5N1 avian influenza and recently spread Ebola. This review presents current developments of using aptamers in the diagnostics and treatment of viral diseases.\n",
            "\n",
            "\n",
            "Title: Strengthening epidemiologic investigation of infectious diseases in Korea: lessons from the Middle East Respiratory Syndrome outbreak\n",
            "Score: 7.361416816711426\n",
            "Abstract: The recent outbreak of Middle East Respiratory Syndrome (MERS) coronavirus infection in Korea resulted in \u001b[31mlarge socioeconomic losses\u001b[39m. This provoked the Korean government and the general public to recognize the importance of having a well-established system against infectious diseases. Although epidemiologic investigation is one of the most important aspects of prevention, it has been pointed out that much needs to be improved in Korea. We review here the current status of the Korean epidemiologic service and suggest possible supplementation measures. We examine the current national preventive infrastructure, including human resources such as Epidemic Intelligence Service officers, its governmental management, and related policies. In addition, we describe the practical application of these resources to the recent MERS outbreak and the progress in preventive measures. The spread of MERS demonstrated that the general readiness for emerging infectious diseases in Korea is considerably low. We believe that it is essential to increase society’s investment in disease prevention. Fostering public health personnel, legislating management policies, and establishing research centers for emerging infectious diseases are potential solutions. Evaluating international preventive systems, developing cooperative measures, and initiating improvements are necessary. We evaluated the Korean epidemiologic investigation system and the public preventive measures against infectious diseases in light of the recent MERS outbreak. We suggest that governmental authorities in Korea enforce preventive policies, foster the development of highly qualified personnel, and increase investment in the public health domain of infectious disease prevention.\n",
            "\n",
            "\n",
            "Title: Engineering a Novel Antibody-Peptide Bispecific Fusion Protein Against MERS-CoV\n",
            "Score: 7.201203346252441\n",
            "Abstract: In recent years, tremendous efforts have been made in the engineering of bispecific or multi-specific antibody-based therapeutics by combining two or more functional antigen-recognizing elements into a single construct. However, to the best of our knowledge there has been no reported cases of effective antiviral antibody-peptide bispecific fusion proteins. We previously developed potent fully human monoclonal antibodies and inhibitory peptides against Middle East Respiratory Syndrome Coronavirus (MERS-CoV), a novel coronavirus that causes \u001b[31msevere acute respiratory illness with high mortality\u001b[39m. Here, we describe the generation of antibody-peptide bispecific fusion proteins, each of which contains an anti-MERS-CoV single-chain antibody m336 (or normal human IgG1 CH3 domain as a control) linked with, or without, a MERS-CoV fusion inhibitory peptide HR2P. We found that one of these fusion proteins, designated as m336 diabody-pep, exhibited more potent inhibitory activity than the antibody or the peptide alone against pseudotyped MERS-CoV infection and MERS-CoV S protein-mediated cell-cell fusion, suggesting its potential to be developed as an effective bispecific immunotherapeutic for clinical use.\n",
            "\n",
            "\n",
            "Title: General hospital staff worries, perceived sufficiency of information and associated psychological distress during the A/H1N1 influenza pandemic\n",
            "Score: 7.122527599334717\n",
            "Abstract: BACKGROUND: Health care workers (HCWs) presented frequent concerns regarding their health and their families' health and high levels of psychological distress during previous disease outbreaks, such as the SARS outbreak, which was associated with \u001b[31msocial isolation and intentional absenteeism\u001b[39m. We aimed to assess HCWs concerns and anxiety, perceived sufficiency of information, and intended behavior during the recent A/H1N1 influenza pandemic and their associations with psychological distress. METHOD: Between September 1(st )and 30(th), 2009, 469 health-care workers (HCWs) of a tertiary teaching hospital completed a 20-item questionnaire regarding concerns and worries about the new A/H1N1 influenza pandemic, along with Cassileth's Information Styles Questionnaire (part-I) and the GHQ-28. RESULTS: More than half of the present study's HCWs (56.7%) reported they were worried about the A/H1N1 influenza pandemic, their degree of anxiety being moderately high (median 6/9). The most frequent concern was infection of family and friends and the health consequences of the disease (54.9%). The perceived risk of being infected was considered moderately high (median 6/9). Few HCWs (6.6%) had restricted their social contacts and fewer (3.8%) felt isolated by their family members and friends because of their hospital work, while a low percentage (4.3%) indented to take a leave to avoid infection. However, worry and degree of worry were significantly associated with intended absenteeism (p < 0.0005), restriction of social contacts (p < 0.0005), and psychological distress (p = 0.036). Perceived sufficiency of information about several aspects of the A/H1N1 influenza was moderately high, and the overall information about the A/H1N1 influenza was considered clear (median 7.4/9). Also, perceived sufficiency of information for the prognosis of the infection was significantly independently associated with the degree of worry about the pandemic (p = 0.008). CONCLUSIONS: A significant proportion of HCWs experienced moderately high anxiety about the pandemic, and their degree of worry was an independent correlate of psychological distress. Since perceived sufficiency of information about the A/H1N1 influenza prognosis was associated with reduced degree of worry, hospital managers and consultation-liaison psychiatry services should try to provide for HCWs' need for information, in order to offer favourable working conditions in times of extreme distress, such as the current and future pandemics.\n",
            "\n",
            "\n",
            "Title: A radical form of nitric oxide inhibits porcine circovirus type 2 replication in vitro\n",
            "Score: 6.74954891204834\n",
            "Abstract: BACKGROUND: Porcine circovirus type 2 (PCV2) is the causal agent of \u001b[31mpostweaning multisystemic wasting syndrome\u001b[39m (PMWS), causing large economical losses of the global swine industry. Nitric oxide (NO), as an important signaling molecule, has antiviral activity on some viruses. To date, there is little information on the role of NO during PCV2 infection. RESULTS: We used indirect fluorescence assay (IFA), TCID(50), real-time RT-qPCR and western blot assay to reveal the role of NO in restricting PCV2 replication. PCV2 replication was inhibited by a form of NO, NO(•), whereas PCV2 was not susceptible to another form of NO, NO(+). CONCLUSION: Our findings indicate that the form of NO(•) has a potential role in the fight against PCV2 infection.\n",
            "\n",
            "\n",
            "Title: Self-disseminating vaccines for emerging infectious diseases\n",
            "Score: 6.697906494140625\n",
            "Abstract: Modern human activity fueled by economic development is profoundly altering our relationship with microorganisms. This altered interaction with microbes is believed to be the major driving force behind the increased rate of emerging infectious diseases from animals. The spate of recent infectious disease outbreaks, including Ebola virus disease and \u001b[31mmiddle east respiratory syndrome\u001b[39m, emphasize the need for development of new innovative tools to manage these emerging diseases. Disseminating vaccines are one such novel approach to potentially interrupt animal to human (zoonotic) transmission of these pathogens.\n",
            "\n",
            "\n",
            "Title: The effect of infection order of porcine circovirus type 2 and porcine reproductive and respiratory syndrome virus on dually infected swine alveolar macrophages\n",
            "Score: 6.6628828048706055\n",
            "Abstract: BACKGROUND: Concurrent infection with porcine circovirus type 2 (PCV2) and porcine reproductive and respiratory syndrome virus (PRRSV) is known as one of the major causes for \u001b[31mporcine respiratory disease complex\u001b[39m (PRDC). Dual infection with PCV2 and PRRSV is consistently to have more severe clinical presentations and pulmonary lesions than infection with PCV2 alone or PRRSV alone. However, it is not known if dual infections with PCV2 and PRRSV in different infection order may lead to different clinical symptoms in the host. To mimic the possible field conditions, swine alveolar macrophages (AMs) were inoculated with PCV2 and PRRSV in vitro simultaneously or with one virus 18 h earlier than the other. The cell viability, cytopathic effects, antigen-containing rates, phagocytotic and microbial killing capabilities, cytokine profiles (IL-8, TNF-α, and IFN-α) and FasL transcripts were determined, analyzed, and compared to prove the hypothesis. RESULTS: A marked reduction in PRRSV antigen-containing rate, cytopathic effect, and TNF-α expression level was revealed in AMs inoculated with PCV2 and PRRSV simultaneously and in AMs inoculated with PCV2 first then PRRSV 18 h later, but not in AMs inoculated with PRRSV first then PCV2 18 h later. Transient decrease in phagocytosis but constant reduction in microbicidal capability in AMs in the group inoculated with PCV2 alone and constant decrease in phagocytosis and microbicidal capability in AMs in all PRRSV-inoculated groups were noted. The levels of IL-8, TNF-α, IFN-α, and FasL transcripts in AMs in all groups with dual inoculation of PCV2 and PRRSV were significantly increased regardless of the infection orders as compared with infection by PCV2 alone or PRRSV alone. CONCLUSIONS: Swine AMs infected with PCV2 first then PRRSV later or infected with PCV2 and PRRSV simultaneously displayed marked reduction in PRRSV antigen-containing rate, cytopathic effect, and TNF-α expression level. The different inoculation orders of PCV2 and PRRSV in AMs leading to different results in viral antigen positivity, cytopathology, and cytokine profile may explain, at least partially, the underlying mechanism of the enhanced pulmonary lesions in PRDC exerted by dual infection with PCV2 and PRRSV and the variable clinical manifestations of PRDC-affected pigs in the field.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHYmSfSrrYN8"
      },
      "source": [
        "#### Extra questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7arwP3eqKwC",
        "outputId": "b6f08c47-d854-4b4f-f9bd-7c6db60913e7"
      },
      "source": [
        "query4 = 'What are most common underlying diseases in covid-19 patients?'\r\n",
        "\r\n",
        "q4_answers, q4_scores = retrieve_all_passages(model, tokenizer, query4, articles_df.abstract)\r\n",
        "q4_best_indices = [i[0] for i in sorted(enumerate(q4_scores), key=lambda x:-x[1])]\r\n",
        "\r\n",
        "display_passages(query4, articles_df, q4_answers, q4_scores, q4_best_indices[:1], 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** The answer-passage is highlighted with red color in the abstract text of each article ***\n",
            "\n",
            "Question: What are most common underlying diseases in covid-19 patients?\n",
            "\n",
            "Title: Neurologic Alterations Due to Respiratory Virus Infections\n",
            "Score: 7.386350631713867\n",
            "Abstract: Central Nervous System (CNS) infections are one of the most critical problems in public health, as frequently patients exhibit neurologic sequelae. Usually, CNS pathologies are caused by known neurotropic viruses such as measles virus (MV), herpes virus and human immunodeficiency virus (HIV), among others. However, nowadays respiratory viruses have placed themselves as relevant agents responsible for CNS pathologies. Among these neuropathological viruses are the human respiratory syncytial virus (hRSV), the influenza virus (IV), the coronavirus (CoV) and the human metapneumovirus (hMPV). These viral agents are leading causes of acute respiratory infections every year affecting mainly children under 5 years old and also the elderly. Up to date, several reports have described the association between respiratory viral infections with neurological symptoms. The most frequent clinical manifestations described in these patients are \u001b[31mfebrile or afebrile seizures, status epilepticus, encephalopathies and encephalitis\u001b[39m. All these viruses have been found in cerebrospinal fluid (CSF), which suggests that all these pathogens, once in the lungs, can spread throughout the body and eventually reach the CNS. The current knowledge about the mechanisms and routes used by these neuro-invasive viruses remains scarce. In this review article, we describe the most recent findings associated to neurologic complications, along with data about the possible invasion routes of these viruses in humans and their various effects on the CNS, as studied in animal models.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB88SeTvqKyt",
        "outputId": "036b6510-120e-4d5f-e89a-343046a1d62b"
      },
      "source": [
        "query5 = 'what are the public measures to control the spread of covid-19?'\r\n",
        "\r\n",
        "q5_answers, q5_scores = retrieve_all_passages(model, tokenizer, query5, articles_df.abstract)\r\n",
        "q5_best_indices = [i[0] for i in sorted(enumerate(q5_scores), key=lambda x:-x[1])]\r\n",
        "\r\n",
        "display_passages(query5, articles_df, q5_answers, q5_scores, q5_best_indices[:3], 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** The answer-passage is highlighted with red color in the abstract text of each article ***\n",
            "\n",
            "Question: what are the public measures to control the spread of covid-19?\n",
            "\n",
            "Title: Local risk perception enhances epidemic control\n",
            "Score: 7.057101249694824\n",
            "Abstract: As infectious disease outbreaks emerge, public health agencies often enact \u001b[31mvaccination and social distancing measures\u001b[39m to slow transmission. Their success depends on not only strategies and resources, but also public adherence. Individual willingness to take precautions may be influenced by global factors, such as news media, or local factors, such as infected family members or friends. Here, we compare three modes of epidemiological decision-making in the midst of a growing outbreak using network-based mathematical models that capture plausible heterogeneity in human contact patterns. Individuals decide whether to adopt a recommended intervention based on overall disease prevalence, the proportion of social contacts infected, or the number of social contacts infected. While all strategies can substantially mitigate transmission, vaccinating (or self isolating) based on the number of infected acquaintances is expected to prevent the most infections while requiring the fewest intervention resources. Unlike the other strategies, it has a substantial herd effect, providing indirect protection to a large fraction of the population.\n",
            "\n",
            "\n",
            "Title: Hepatitis C virus modelled as an indirectly transmitted infection highlights the centrality of injection drug equipment in disease dynamics\n",
            "Score: 6.673881530761719\n",
            "Abstract: The hepatitis C virus (HCV) epidemic often occurs through the persistence of injection drug use. Mathematical models have been useful in understanding various aspects of the HCV epidemic, and especially, the importance of new treatment measures. Until now, however, few models have attempted to understand HCV in terms of an interaction between the various actors in an HCV outbreak—hosts, viruses and the needle injection equipment. In this study, we apply perspectives from the ecology of infectious diseases to model the transmission of HCV among a population of injection drug users. The products of our model suggest that modelling HCV as an indirectly transmitted infection—where the injection equipment serves as an environmental reservoir for infection—facilitates a more nuanced understanding of disease dynamics, by animating the underappreciated actors and interactions that frame disease. This lens may allow us to understand how certain public health interventions (e.g. \u001b[31mneedle exchange programmes\u001b[39m) influence HCV epidemics. Lastly, we argue that this model is of particular importance in the light of the modern opioid epidemic, which has already been associated with outbreaks of viral diseases.\n",
            "\n",
            "\n",
            "Title: Effectiveness of traveller screening for emerging pathogens is shaped by epidemiology and natural history of infection\n",
            "Score: 6.210239410400391\n",
            "Abstract: During outbreaks of high-consequence pathogens, \u001b[31mairport screening programs\u001b[39m have been deployed to curtail geographic spread of infection. The effectiveness of screening depends on several factors, including pathogen natural history and epidemiology, human behavior, and characteristics of the source epidemic. We developed a mathematical model to understand how these factors combine to influence screening outcomes. We analyzed screening programs for six emerging pathogens in the early and late stages of an epidemic. We show that the effectiveness of different screening tools depends strongly on pathogen natural history and epidemiological features, as well as human factors in implementation and compliance. For pathogens with longer incubation periods, exposure risk detection dominates in growing epidemics, while fever becomes a better target in stable or declining epidemics. For pathogens with short incubation, fever screening drives detection in any epidemic stage. However, even in the most optimistic scenario arrival screening will miss the majority of cases. DOI: http://dx.doi.org/10.7554/eLife.05564.001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgwnXpGjFFqE"
      },
      "source": [
        "**As we mentioned above, simple BERT models such as DistilBERT seem pretty weak in dealing with complicated tasks like questionanswering. So we had to give them a little boost in order to succeed in our QA task. To achieve that we had to use the pretrained `bert-large-uncased-whole-word-masking-finetuned-squad` model, which is basically the BERT-large model that has already been fine-tuned for the SQuAD benchmark. SQuAD dataset, is a reading comprehension dataset, implemented in Stanford in order to accomplish QA tasks. It consists of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage. In some cases the question might be unanswerable. SQuAD offers around 150,000 questions, which is not that much in the deep learning world but it still does the trick for simpler QA task like ours. We should also have in mind that BERT-large is a really big model consisting of 24 layers and an embedding size of 1024, for a total of 340M parameters. As a result, the BERT-large and SQuAD combination lead to a much more time consuming execution compared to the DistilBERT one.**\r\n",
        "\r\n",
        "**In our first experiment with our new model we can already observe a clear improvement both on score and retrieved passage terms, even though it takes much longer to respond. We can see that for the question 'What are the coronaviruses?' our model responds with a very convincing passage from the article 'Infectious Bronchitis Virus Nonstructural Protein 4 Alone Induces Membrane Pairing', which is highlighted with red color in the article's body text (abstract). According to this article coronaviruses are 'positive-strand rna viruses', which is a pretty accurate answer with a score of 8.6403. In fact, this score is by far the best score we get among all the QAs we experiment with and it shows that the question we posed is simple yet primary, as we can find an answer about it in most of the articles of the dataset. In our following experiments we try to pose more complex questions and we seek for more than one possible answers. For instance, in our third experiment we pose the question 'What is caused by SARS-COV2?' and we ask for the 10 best answers. The best answer with a score of 7.8293 is 'chronic liver disease' and it's a correct answer. However, the third answer with almost the same score (7.6833) is 'severe acute respiratory syndrome' a.k.a. 'SARS', which is ,of course, inaccurate. Therefore, sometimes a high score doesn't automatically imply a correct answer. This is a logical conclusion specially when we seek for the best passages among multiple articles. In fact, this conclusion  can be verified in our second example where we ask 'What is Coronavirus Disease 2019?' and the best answer is 'severe diarrhea', with a high score of 8.0050, which means that the model answers with high certainty but in practice it returns an inaccurate passage. The paradox is that all the next answers of the question have also high score values, between 7 and 8. Another assumption we can make is that there are actually better answers for the query but the model is missleaded by the original question and ends up answering a different one. An important factor that can cause the model's deception is the filtering that we apply on the dataset. For example, if a query's keyword isn't included in the filtering keywords, there is a big chance that articles that could answer the query are filtered out of the database. Keywords can, substantially, particularize the type of questions that a model can answer. Yet, this doesn't seem to be the case in our third experiment, as keywords 'coronavirus' and 'disease' are used in our filtering process. After all, it's hard to know what is the reason behind the model's incapability to answer a simple question like that after having already answered a very similar question, 'What are the coronaviruses?'. To sum up, a BERT model that is fine-tuned on the SQuAD dataset leads to much better QA results. However, there are many factors that can expose this model's weaknesses.**"
      ]
    }
  ]
}